{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the dependencies\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import datetime\n",
    "from urllib.parse import urljoin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methodology for the Weather Maps\n",
    "\n",
    "The Weather Prediction Center of the National Weather Service (NOAA) maintains historical weather maps including analyses with radar and satellite imagery.  We can scrape these maps with BeautifulSoup once we inspect the HTML elements of the site:\n",
    "[https://www.wpc.ncep.noaa.gov/archives/web_pages/sfc/sfc_archive_maps.php?arcdate=07/04/2019&selmap=2019070421&maptype=ussatsfc](https://www.wpc.ncep.noaa.gov/archives/web_pages/sfc/sfc_archive_maps.php?arcdate=07/04/2019&selmap=2019070421&maptype=ussatsfc)  \n",
    "\n",
    "We can then adjust the dates and hour in the url to select the maps for each snow event.  The coding of the dates is straight forward.  The inclusion of time is subtle - the maps are only provided in 3 hour increments starting with 00, 03, 06, 09, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_weather_url(date, hour):\n",
    "    \"\"\"Build up the url from the date and hour\"\"\"\n",
    "    base_url = \"https://www.wpc.ncep.noaa.gov/archives/web_pages/sfc/sfc_archive_maps.php?arcdate=\"\n",
    "    mid_url = \"&selmap=\"\n",
    "    tail_url = \"&maptype=ussatsfc\"\n",
    "    \n",
    "    arcdate = date.strftime(\"%m/%d/%Y\")\n",
    "    seldate = date.strftime(\"%Y%m%d\")\n",
    "    selmap = seldate + str(hour).zfill(2)\n",
    "    \n",
    "    return base_url + arcdate + mid_url + selmap + tail_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather_gif_url(date, hour):\n",
    "    \"\"\"Grab the url for the satellite/surface image\"\"\"\n",
    "    page_url = build_weather_url(date, hour)\n",
    "    \n",
    "    # define a default gif_url that will be returned if request fails\n",
    "    gif_url = \"\"\n",
    "    \n",
    "    try:\n",
    "        page_response = requests.get(page_url,timeout=5)\n",
    "        page_response.raise_for_status()\n",
    "    except requests.exceptions.HTTPError as errh:\n",
    "        print (\"Http Error:\",errh)\n",
    "    except requests.exceptions.ConnectionError as errc:\n",
    "        print (\"Error Connecting:\",errc)\n",
    "    except requests.exceptions.Timeout as errt:\n",
    "        print (\"Timeout Error:\",errt)\n",
    "    except requests.exceptions.RequestException as err:\n",
    "        print (\"OOps: Something Else\",err)\n",
    "    else:\n",
    "        page_content = BeautifulSoup(page_response.content, \"html.parser\")\n",
    "    \n",
    "        image_rel_url = page_content.find_all('img',attrs={\"class\":\"sfcmapimage\"})[0][\"src\"]\n",
    "\n",
    "        gif_url = urljoin(page_url, image_rel_url)\n",
    "    \n",
    "    return gif_url\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.wpc.ncep.noaa.gov/archives/sfc/2018/ussatsfc2018012212.gif'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_weather_gif_url(datetime.datetime(2018, 1, 22, 0, 0), 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_weather_gif(date, hour, emergency):\n",
    "    \"\"\"Download the satellite/surface image\"\"\"\n",
    "    \n",
    "    gif_url = get_weather_gif_url(date, hour)\n",
    "    \n",
    "    seldate = date.strftime(\"%Y%m%d\")\n",
    "    selmap = \"static/img/\" + emergency + seldate + str(hour).zfill(2) + '.gif'\n",
    "    \n",
    "    with open(selmap, 'wb') as gif_file:\n",
    "        gif_file.write(requests.get(gif_url).content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_weather_gif(datetime.datetime(2018, 1, 22, 0, 0), 12, 'Pembina')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "episodes_df = pd.read_csv('static/data/episodes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emergency</th>\n",
       "      <th>event_id</th>\n",
       "      <th>county</th>\n",
       "      <th>storm_begin_date</th>\n",
       "      <th>begin_time</th>\n",
       "      <th>declaration_date</th>\n",
       "      <th>type</th>\n",
       "      <th>episode_id</th>\n",
       "      <th>narrative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Grant</td>\n",
       "      <td>606010.0</td>\n",
       "      <td>Scott</td>\n",
       "      <td>12/28/2015</td>\n",
       "      <td>18</td>\n",
       "      <td>12/29/2015</td>\n",
       "      <td>Winter Storm</td>\n",
       "      <td>101309.0</td>\n",
       "      <td>A very large storm system that began in the so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Polk</td>\n",
       "      <td>610886.0</td>\n",
       "      <td>Hennepin</td>\n",
       "      <td>2/2/2016</td>\n",
       "      <td>12</td>\n",
       "      <td>2/2/2016</td>\n",
       "      <td>Winter Storm</td>\n",
       "      <td>102020.0</td>\n",
       "      <td>A major winter storm affected the Upper Midwes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dana</td>\n",
       "      <td>662543.0</td>\n",
       "      <td>Carver</td>\n",
       "      <td>12/10/2016</td>\n",
       "      <td>12</td>\n",
       "      <td>12/11/2016</td>\n",
       "      <td>Winter Storm</td>\n",
       "      <td>111012.0</td>\n",
       "      <td>A storm system began to develop across the Pla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ferry</td>\n",
       "      <td>662658.0</td>\n",
       "      <td>Hennepin</td>\n",
       "      <td>12/16/2016</td>\n",
       "      <td>15</td>\n",
       "      <td>12/17/2016</td>\n",
       "      <td>Winter Storm</td>\n",
       "      <td>111065.0</td>\n",
       "      <td>A long duration snow storm that occurred from ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jane</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/9/2017</td>\n",
       "      <td>12</td>\n",
       "      <td>1/11/2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  emergency  event_id    county storm_begin_date  begin_time declaration_date  \\\n",
       "0     Grant  606010.0     Scott       12/28/2015          18       12/29/2015   \n",
       "1      Polk  610886.0  Hennepin         2/2/2016          12         2/2/2016   \n",
       "2      Dana  662543.0    Carver       12/10/2016          12       12/11/2016   \n",
       "3     Ferry  662658.0  Hennepin       12/16/2016          15       12/17/2016   \n",
       "4      Jane       NaN       NaN         1/9/2017          12        1/11/2017   \n",
       "\n",
       "           type  episode_id                                          narrative  \n",
       "0  Winter Storm    101309.0  A very large storm system that began in the so...  \n",
       "1  Winter Storm    102020.0  A major winter storm affected the Upper Midwes...  \n",
       "2  Winter Storm    111012.0  A storm system began to develop across the Pla...  \n",
       "3  Winter Storm    111065.0  A long duration snow storm that occurred from ...  \n",
       "4           NaN         NaN                                                     "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "episodes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from dateutil.parser import parse\n",
    "\n",
    "def convert_dates(dates):\n",
    "    def try_to_parse_date (a_string):\n",
    "        try:\n",
    "            parsed = parse(a_string, fuzzy_with_tokens=True)\n",
    "        except ValueError:\n",
    "            print(f\"Could not parse a date from `{a_string}`\")\n",
    "        else:\n",
    "            return parsed[0]\n",
    "        \n",
    "    def converter(date):\n",
    "        if isinstance(date, datetime.datetime):\n",
    "            return date\n",
    "        else:\n",
    "            return try_to_parse_date(date)\n",
    "    \n",
    "    return [converter(date) for date in dates]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "episodes_df['storm_begin_date'] = convert_dates(episodes_df['storm_begin_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "episodes_df['declaration_date'] = convert_dates(episodes_df['declaration_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We could do some pre-scraping to save the url for the image in the dataframe\n",
    "\n",
    "gif_url = []\n",
    "\n",
    "for row in episodes_df.itertuples():\n",
    "    gif_url.append( get_weather_gif_url(row.storm_begin_date, row.begin_time) )\n",
    "    \n",
    "episodes_df['gif_url'] = gif_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As a backup, we could also pre-scrape the images:\n",
    "\n",
    "for row in episodes_df.itertuples():\n",
    "    download_weather_gif(row.storm_begin_date, row.begin_time, row.emergency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Armatage2019022409.gif',\n",
       " 'Dana2016121012.gif',\n",
       " 'Diamond Lake2019030915.gif',\n",
       " 'Ferry2016121615.gif',\n",
       " 'Grant2015122818.gif',\n",
       " 'Howe2018041321.gif',\n",
       " 'Howe22018041409.gif',\n",
       " 'Jane2017010912.gif',\n",
       " 'Olive2018011412.gif',\n",
       " 'Pembina2018012209.gif',\n",
       " 'Pembina2018012212.gif',\n",
       " 'Polk2016020212.gif',\n",
       " 'Quincy2019012718.gif',\n",
       " 'Upton2019020706.gif',\n",
       " 'Wesminster2019021006.gif',\n",
       " 'Xerxes2018022212.gif',\n",
       " 'Yale2019022003.gif',\n",
       " 'Yardville2018022415.gif']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('static/img')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In conclusion:\n",
    "\n",
    "We can define an app route that fetches the historical weather maps using the above functions.  We could pull the image each time or load from the `static/img` directory. Another option would allow the user to pick the date and time (recall the time increments 00, 03, 06, 09) for the weather map from a menu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the work we did to convert the dates and fetch the URLs\n",
    "episodes_df.to_csv('static/data/finalEpisodes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonWebMongo]",
   "language": "python",
   "name": "conda-env-PythonWebMongo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
